import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
from torchvision import datasets, models, transforms
import os
import numpy as np
import matplotlib.pyplot as plt
import time
from glob import glob
from PIL import Image

# GPU 사용 여부 확인
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

# 데이터 전처리 및 augmentation 설정
transforms_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

transforms_test = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# 데이터 경로 설정
data_dir = r'C:\Users\syu\jimin\jimin'
train_datasets = datasets.ImageFolder(os.path.join(data_dir, 'train'), transforms_train)
train_dataloader = torch.utils.data.DataLoader(train_datasets, batch_size=4, shuffle=True, num_workers=0)

print('학습 데이터셋 크기:', len(train_datasets))
class_names = train_datasets.classes
print('클래스:', class_names)

# 이미지 시각화 함수
def imshow(input, title):
    input = input.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    input = std * input + mean
    input = np.clip(input, 0, 1)
    plt.imshow(input)
    plt.title(title)
    plt.show()

# 모델 정의 및 전이 학습
model = models.resnet34(pretrained=True)
num_features = model.fc.in_features

model.fc = nn.Sequential(
    nn.Linear(num_features, 256),
    nn.ReLU(),
    nn.Dropout(0.4),
    nn.Linear(256, len(class_names)),
    nn.LogSoftmax(dim=1)
)

criterion = nn.NLLLoss()
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-5)

model = model.to(device)

num_epochs = 30
best_epoch = None
best_loss = float('inf')

# 손실 및 정확도 기록
train_losses = []
train_accuracies = []

# 훈련 루프
for epoch in range(num_epochs):
    model.train()
    start_time = time.time()
    running_loss = 0.
    running_corrects = 0

    for inputs, labels in train_dataloader:
        inputs = inputs.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        loss = criterion(outputs, labels)

        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

    epoch_loss = running_loss / len(train_datasets)
    epoch_acc = running_corrects.double() / len(train_datasets)
    
    train_losses.append(epoch_loss)
    train_accuracies.append(epoch_acc)
    
    print('#{} Loss: {:.4f} Acc: {:.4f} Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))

    if epoch_loss < best_loss:
        best_loss = epoch_loss
        best_epoch = epoch

print("Best Loss: {:.4f}, Best Epoch: {}".format(best_loss, best_epoch))

# 손실 값과 정확도의 추이 그래프 출력
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss Over Epochs')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy Over Epochs')
plt.legend()

plt.tight_layout()
plt.show()

# 가중치 저장
os.makedirs('./weight', exist_ok=True)
torch.save(model, './weight/model_best_epoch.pt')

# 테스트
valid_images = []
valid_dir = os.path.join(data_dir, 'test')
val_folders = glob(valid_dir + '/*')
for val_folder in val_folders:
    image_paths = glob(val_folder + '/*')
    for image_path in image_paths:
        valid_images.append(image_path)

# 무작위 이미지 선택 및 테스트
random_idx = np.random.randint(0, len(valid_images))
valid_image = valid_images[random_idx]

image = Image.open(valid_image)
image = transforms_test(image).unsqueeze(0).to(device)

with torch.no_grad():
    outputs = model(image)
    _, preds = torch.max(outputs, 1)
    
imshow(image.cpu().data[0], title='예측 클래스: ' + class_names[preds[0]])
